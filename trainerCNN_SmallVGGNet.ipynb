{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Convolutional Neural Network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras doc: https://keras.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallVGGNet:\n",
    "    \n",
    "    def build(width, height, channel, classes):\n",
    "        model = Sequential()\n",
    "        inputShape =(height, width, channel)\n",
    "        chanDim = -1\n",
    "        \n",
    "        # if we are using \"channels first\", update the input shape and channels dimension\n",
    "        if backend.image_data_format()== \"channel_first\":\n",
    "            inputShape =(channel , height, width)\n",
    "            chanDim = 1\n",
    "        \n",
    "        # CONV => RELU => POOL layer set *3 layer set\n",
    "        model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=inputShape))\n",
    "        model.add(tActivation(\"relu\")) #Rectified Linear Unit\n",
    "        \n",
    "        #Batch Normalization is used to normalize the activations of a given input volume before passing it to the next layer in the network.\n",
    "        #It has been proven to be very effective at reducing the number of epochs required to train a CNN as well as stabilizing training itself.\n",
    "        model.add(BatchNormalization(axis = chanDim))\n",
    "        \n",
    "        #progressively reducing the spatial size\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "        #25% of the node connections are randomly disconnected (dropped out) between layers during each training iteration.\n",
    "        model.add(Dropout(.25)) #concept not to be overlooked\n",
    "        \n",
    "        \n",
    "        # (CONV => RELU) * 2 => POOL layer set\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis= chanDim))\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis= chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        #increasing the total number of filters learned from 32 to 64. remainning same dimensions(3x3)\n",
    "        # (CONV => RELU) * 3 => POOL layer set\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        #deeper you go into a CNN (and as your input volume size becomes smaller and smaller) is common practice.\n",
    "        \n",
    "        \n",
    "        #FC => RELU\n",
    "        # set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis= chanDim))\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "        #softMax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        \n",
    "        \n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
